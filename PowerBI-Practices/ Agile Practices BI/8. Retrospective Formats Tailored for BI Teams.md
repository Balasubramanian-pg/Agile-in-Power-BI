# Retrospective Formats Tailored for BI Teams

## Fundamentals: Why BI Retrospectives Need a Special Focus

### Definition and Purpose

*   A retrospective is a recurring meeting in Agile methodologies where a team reflects on a completed work period (a sprint) to identify opportunities for improvement. The goal is to answer three core questions: What went well? What didn't go well? What will we change?
*   For Business Intelligence (BI) teams, a standard retrospective is a good start, but it often misses the unique challenges inherent in data and analytics work.
*   **A BI-tailored retrospective** is a format specifically designed to facilitate conversations around data-specific challenges, such as data quality, upstream dependencies, stakeholder communication, and the balance between planned projects and ad-hoc requests.

### Unique Challenges for BI Teams

Standard retrospective formats can fail to unearth the root causes of issues in a BI context. Tailored formats are needed to address challenges like:

*   **Data Dependencies and Upstream Delays**: BI work is often blocked by the availability and structure of data from other teams (e.g., data engineering, platform teams).
*   **Data Quality and Trust**: Unexpected issues in source data can derail a sprint and erode stakeholder confidence.
*   **Vague or Evolving Requirements**: Stakeholders often "discover what they want" only after seeing initial visualizations, leading to significant rework.
*   **The Ad-Hoc Request Barrage**: Constant, urgent requests for data can disrupt sprint commitments and lead to team burnout.
*   **Complex Technical Environments**: Managing intricate data models, ETL/ELT pipelines, and various reporting tools adds a layer of complexity not always present in typical software development.
*   **Defining "Done"**: It can be difficult to define and test the acceptance criteria for a BI story, which may involve subjective analytical value as well as objective data points.

> [!NOTE]
> The primary goal of tailoring a retrospective is to move beyond generic process discussions and create a safe, structured space to tackle the specific, recurring pain points of BI development.

## Tailored Retrospective Formats for BI Teams

The following formats adapt popular retrospective techniques with prompts and focus areas specifically designed for BI and analytics teams.

### 1. The "Data Flow" Retrospective (Adapted from Timeline/Journey Mapping)

This format visualizes the entire process from business question to delivered insight, helping to pinpoint bottlenecks and communication gaps.

*   **Best For**: Identifying hidden dependencies, process inefficiencies, and communication breakdowns across the entire data value chain.
*   **How to Run It**:
    1.  **Draw the Flow**: On a whiteboard, draw a high-level timeline of your BI process. Label key stages, such as: `Business Request` -> `Backlog Refinement` -> `Data Sourcing/Access` -> `ETL/Modeling` -> `Dashboard Dev` -> `UAT/Feedback` -> `Delivery`.
    2.  **Plot the Sprint's Events**: Team members use sticky notes to add significant events from the sprint onto the timeline. Encourage them to be specific.
        *   **Green Stickies (Accelerators)**: What went smoothly or faster than expected? (e.g., "Received access to the new API ahead of schedule.")
        *   **Red Stickies (Blockers)**: Where did we get stuck or delayed? (e.g., "Waited three days for the upstream pipeline to be fixed," "Discovered major data quality issues during UAT.")
    3.  **Discuss the Patterns**: As a group, look at the board.
        *   Where do the red stickies cluster? This is your primary bottleneck.
        *   What patterns emerge? Is the `Data Sourcing` stage always a blocker? Is feedback during `UAT` consistently causing major rework?
*   **BI-Specific Prompts**:
    *   "At what stage did we have the least clarity on the requirements?"
    *   "Where did a dependency on another team slow us down the most?"
    *   "At what point in the flow did we discover a critical data quality issue?"
    *   "Was there a moment when communication with the stakeholder broke down? Where was it?"

### 2. The "4Ls" Retrospective for BI (Liked, Learned, Lacked, Longed For)

This classic format is adapted to focus on BI-specific experiences, balancing positive and negative reflections.

*   **Best For**: A well-rounded review that captures team sentiment, knowledge gaps, and specific needs related to data, tools, and processes.
*   **How to Run It**:
    1.  **Create Four Quadrants**: Divide a whiteboard into four sections: `Liked`, `Learned`, `Lacked`, `Longed For`.
    2.  **Silent Brainstorming**: Give the team 10 minutes to write their thoughts on sticky notes for each category, using BI-specific prompts.
    3.  **Group and Discuss**: Team members place their notes in the respective quadrants. The facilitator groups similar themes and leads a discussion on the most prominent topics.
*   **BI-Specific Prompts**:
    *   **Liked**: "What part of our data stack or toolset made your job easier this sprint?" "Which collaboration with a stakeholder was particularly effective?"
    *   **Learned**: "What did we learn about a new data source?" "What new query optimization technique did we discover?" "What did we learn about our users' analytical needs?"
    *   **Lacked**: "What data did we lack that would have made this dashboard more valuable?" "What skills (e.g., DAX, SQL, data modeling) did we feel we were missing?" "What clear acceptance criteria did we lack for a story?"
    *   **Longed For**: "What automated data quality test do you wish we had?" "What self-service tool do you wish our stakeholders had to reduce ad-hoc requests?" "What access to a source system do you long for?"

### 3. The "Anchors and Engines" Retrospective (Adapted from Sailboat)

A metaphorical format that helps the team think about what is holding them back and what is propelling them forward in their BI delivery.

*   **Best For**: A more engaging and visual way to discuss risks, dependencies, and drivers of success.
*   **How to Run It**:
    1.  **Draw the Scene**: Draw a large sailboat on a whiteboard. Add an island in the distance (the sprint goal), rocks below the water, an anchor dragging behind the boat, and wind in the sails.
    2.  **Brainstorm with Metaphors**: The team uses sticky notes to populate the drawing.
    3.  **Discuss and Generate Actions**: Focus the discussion on two key areas: How can we mitigate the risks (rocks)? And how can we reduce the drag (anchors)?
*   **BI-Specific Prompts**:
    *   **The Island (Goal)**: "How well did our delivered dashboards align with the sprint goal we set out to achieve?"
    *   **The Wind (Engines/Propellers)**: "What processes, tools, or team collaborations pushed us forward?" "Did our automated testing suite help us move faster?"
    *   **The Anchors (Drag/Slowdowns)**: "What internal processes slowed us down (e.g., manual deployment, code reviews)?" "Which ad-hoc requests pulled us away from our sprint commitment?" "Was our backlog refinement process a drag?"
    *   **The Rocks (Risks/Blockers)**: "What future data dependencies do we see on the horizon?" "What potential data quality issues could sink our next sprint?" "What stakeholder disagreements are a risk to the project?"

### 4. The Data-Driven/Metrics-Focused Retrospective

This format moves away from subjective feelings and focuses the conversation on objective data and key performance indicators from the sprint.

*   **Best For**: Mature teams that want to make evidence-based decisions for improvement and are tired of retrospectives that are purely based on perception.
*   **How to Run It**:
    1.  **Prepare the Data**: Before the meeting, the Scrum Master or a team member gathers relevant metrics from the sprint.
    2.  **Present the Data**: Start the retrospective by presenting charts and numbers without judgment. Let the team absorb the information.
    3.  **Ask "Why?"**: Use the "5 Whys" technique to drill down into the reasons behind the numbers. The goal is to find the root cause, not to place blame.
    4.  **Formulate Hypotheses for Improvement**: Frame action items as experiments. "We hypothesize that if we dedicate 4 hours to proactive data profiling at the start of a story, we can reduce data-related bugs by 25%."
*   **Key BI Metrics to Track**:
    *   **Cycle Time**: How long does it take from when a story is started to when it's delivered? Where are the longest delays?
    *   **Planned-to-Done Ratio**: How many of the stories we committed to did we actually complete?
    *   **Ad-hoc vs. Planned Work Ratio**: What percentage of our time was spent on unplanned requests? Is this ratio trending up or down?
    *   **Number of Data-Related Bugs**: How many bugs were caused by issues in the source data vs. errors in our own logic?
    *   **Rework Rate**: How many stories had to be significantly reworked after the sprint review due to misunderstood requirements?

> [!CAUTION]
> When using a data-driven approach, it is crucial to create a psychologically safe environment. The data should be used to improve the process, not to blame individuals or teams for poor numbers.

## Flashcard-Style Q&A

*   **Q: Why do BI teams need specialized retrospective formats?**
    *   **A:** Because they face unique, recurring challenges like data dependencies, data quality issues, and a high volume of ad-hoc requests that standard formats often fail to address effectively.

*   **Q: What is the main goal of the "Data Flow" retrospective?**
    *   **A:** To visualize the entire BI value chain (from request to delivery) and identify where process bottlenecks, blockers, and communication gaps are occurring.

*   **Q: In the "Anchors and Engines" format, what does the "Anchor" typically represent for a BI team?**
    *   **A:** It represents things that slow the team down, such as manual processes, technical debt in the data model, or the constant drag of disruptive ad-hoc requests.

*   **Q: When adapting the "4Ls" format for a BI team, what is a good prompt for the "Lacked" category?**
    *   **A:** "What data, tool, or skill did we lack that prevented us from delivering more value?" or "What clear acceptance criteria did we lack for a story?"

*   **Q: What is a key benefit of a "Data-Driven Retrospective"?**
    *   **A:** It shifts the conversation from subjective feelings and perceptions to objective, evidence-based problem-solving, helping the team identify the real root causes of issues.

*   **Q: What is a critical prerequisite for running a successful data-driven retrospective?**
    *   **A:** A high level of psychological safety. The team must trust that the metrics will be used to improve the system and not to assign individual blame.
