# Measuring Sprint Velocity for BI Work

## Fundamentals: What is Sprint Velocity and Why Does it Matter?

### Definition and Core Concept

*   **Sprint Velocity** is a measure of the amount of work a Business Intelligence (BI) team successfully completes during a single sprint.
*   It is not a measure of time or a guarantee, but rather a historical average of the team's recent output.
*   Velocity is typically measured in **Story Points**, which are a relative, abstract measure of the effort, complexity, and uncertainty involved in completing a user story.
*   The key principle is that velocity is a **historical observation**, not a target. It is calculated by averaging the total number of story points from all *fully completed* user stories over the last 3-4 sprints.

### The Core Purpose for a BI Team

Velocity is one of the most important metrics for an Agile BI team, but its purpose is often misunderstood. Its primary uses are:

1.  **Forecasting and Predictability**: Velocity allows a team to make reasonable forecasts about the future. If the product backlog has 200 story points of work and the team's average velocity is 20 points per sprint, the team can forecast that it will take approximately 10 sprints to complete that work. This is invaluable for roadmap planning and managing stakeholder expectations.
2.  **Making Realistic Sprint Commitments**: During sprint planning, the team's historical velocity serves as a crucial guide for how much work they can realistically commit to in the upcoming sprint. This helps prevent over-commitment, which leads to burnout and missed goals.
3.  **A Barometer for Process Improvement**: A stable or gradually increasing velocity can indicate a healthy, improving process. A sudden, sustained drop in velocity is a powerful signal that there is a systemic problem (like new technical debt, unresolved dependencies, or team burnout) that needs to be addressed in a retrospective.

> [!IMPORTANT]
> **Velocity is a forecasting tool, NOT a performance metric.** It is a measure of a team's capacity, not its productivity or value. Using velocity to judge individual performance or to compare different teams is a misuse of the metric and a destructive anti-pattern.

## How to Calculate and Use Velocity: A Step-by-Step Guide

### Step 1: Have a Consistent Estimation Process

*   Before you can measure velocity, your team must be consistently estimating the size of your backlog items (user stories) in story points.
*   This is typically done during backlog refinement using a consensus-based technique like **Planning Poker**.
*   The key is consistency. The value of the points is relative *to that specific team*. A 5-point story should feel roughly half the effort of a 10-point story *to your team*.

### Step 2: Have a Strong Definition of Done (DoD)

*   The team must have a clear, shared understanding of what it means for a story to be **"done."**
*   A BI-specific DoD might include:
    *   Code is committed to the main branch.
    *   All automated tests (data quality, unit tests) are passing.
    *   The data dictionary and other documentation are updated.
    *   The report has been validated by the Product Owner and/or key stakeholders (UAT).
*   **Crucially, no partial credit is given.** A story that is 99% complete is worth 0 points toward the sprint's velocity calculation.

### Step 3: Sum the Points at the End of the Sprint

*   At the conclusion of each sprint, sum the story points for **only the user stories that met 100% of the Definition of Done.**
*   This number is the "points completed" for that specific sprint.

### Step 4: Calculate the Rolling Average

*   Velocity is not the number from a single sprint, as this can fluctuate.
*   Calculate a rolling average of the points completed over the last 3-4 sprints. This smooths out natural variations and provides a more stable, reliable number.
*   **Example**:
    *   Sprint 1: Completed 25 points
    *   Sprint 2: Completed 30 points
    *   Sprint 3: Completed 28 points
    *   **The team's current velocity is (25 + 30 + 28) / 3 = 27.7, or ~28 points.**

### Step 5: Use Velocity to Plan the Next Sprint

*   In the next sprint planning meeting, the team can look at their velocity of 28 and use it as a capacity guideline. They should be cautious about pulling more than 28 points of work into the sprint, as historical data suggests this is their sustainable pace.

## The Unique Challenges of Measuring Velocity in BI

BI work presents several challenges that can make velocity fluctuate more than in typical software development. The key is not to eliminate fluctuation, but to understand it.

*   **Unplanned Ad-Hoc Work**:
    *   **The Problem**: Stakeholders frequently make urgent, unplanned requests that are not estimated and disrupt the sprint plan.
    *   **The Solution**: Make this work visible.
        1.  **Track Everything**: All ad-hoc work must be logged as a task.
        2.  **Estimate on the Fly**: Quickly estimate the size of the ad-hoc task in story points.
        3.  **Count it**: Include the points from completed ad-hoc tasks in your velocity calculation. This gives you a true measure of your team's total output.
        4.  **Analyze the Ratio**: Use the ratio of planned vs. unplanned points as a key discussion topic in your retrospective.
*   **Spikes and Data Discovery**:
    *   **The Problem**: A significant amount of BI work involves research, data profiling, and feasibility analysis (spikes) that don't result in a direct, user-facing feature.
    *   **The Solution**: Estimate and timebox your spikes. A spike story is an agreement to invest a fixed amount of time to answer a question. The team can assign story points to it based on the effort and complexity of the research. The "deliverable" is the answer to the question, which allows the team to then properly estimate the implementation story.
*   **External Dependencies**:
    *   **The Problem**: A BI story is often blocked waiting for an upstream data engineering team to deliver a new data source. A blocked story cannot be completed and will contribute 0 points to velocity.
    *   **The Solution**: This is a feature, not a bug, of velocity. The resulting drop in velocity makes the pain of the dependency visible and quantifiable. It provides concrete evidence for the Scrum Master and Product Owner to take to leadership and say, "Our team's delivery is being impacted by these external blockers, and we need to solve this process issue."
*   **Variability of Work**:
    *   **The Problem**: One sprint might involve deep, complex data modeling (high point values, few stories), while the next involves simple UI tweaks to a dashboard (low point values, many stories).
    *   **The Solution**: Trust the average. This is why using a rolling average over several sprints is so important. It smooths out these natural peaks and valleys in the type of work being done.

## Common Pitfalls and Anti-Patterns (How NOT to Use Velocity)

| Pitfall / Anti-Pattern | Why It's Harmful | The Correct Approach |
| :--- | :--- | :--- |
| **Comparing Velocity Between Teams** | Story points are a team-specific, relative measure. Team A's "8 points" is not the same as Team B's "8 points." Comparing them is meaningless and fosters unhealthy competition. | Velocity is a tool for a team to understand *itself*. It should never be used as a cross-team comparison metric. |
| **Using Velocity as a Performance Metric** | When managers reward "higher velocity," the team will inevitably start inflating their story point estimates to make the numbers go up. This destroys the metric's value for forecasting. | Focus on the business value delivered, not the number of points completed. Velocity is a capacity measure, not a value measure. |
| **Giving Partial Credit for Incomplete Stories** | This makes the velocity number unpredictable and unreliable. If a 10-point story is "half done," carrying 5 points over gives a false sense of progress and breaks forecasting. | A story is either 100% done or it is 0% done. The entire point value of an incomplete story should be carried over and re-estimated (if necessary) in the next sprint. |
| **Ignoring Fluctuations** | Panicking after one "low" sprint or celebrating after one "high" sprint is a reactive mistake. | Look at the trend over time. A sustained downward trend is a signal to investigate root causes in a retrospective. A single data point is just noise. |

## Flashcard-Style Q&A

*   **Q: What is sprint velocity?**
    *   **A:** A measure of the amount of work (in story points) that a team has historically completed within a sprint. It is calculated as a rolling average of the last 3-4 sprints.

*   **Q: What is the primary purpose of measuring velocity?**
    *   **A:** To provide a reliable basis for forecasting future work (roadmap planning) and for making realistic commitments during sprint planning.

*   **Q: What is velocity NOT used for?**
    *   **A:** It is NOT a measure of productivity, and it should never be used to compare teams or to evaluate individual performance.

*   **Q: How should a BI team account for unplanned ad-hoc work in their velocity?**
    *   **A:** They should make all ad-hoc work visible by logging it, estimating it in story points, and including the points from completed ad-hoc tasks in their velocity calculation.

*   **Q: What does a sudden, sustained drop in a BI team's velocity indicate?**
    *   **A:** It is a strong signal of a systemic impediment, such as unresolved external dependencies, accumulating technical debt, or team burnout, which needs to be addressed.
